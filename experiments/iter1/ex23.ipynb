{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9249ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from experiments.iter1.util.importer_TCN import *\n",
    "MODEL_PATH = 'model_saves/ex23_model'\n",
    "nist_path = \"../../src/data_preprocess/dataset/NIST_cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fdbb295a777435290b2d87b0267bcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35aae918558d46a5a09d04c42b28ed7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f16e67aad441a1b635b6bd09e11a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31efd2caaf044f3483dc66a441cb7aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf8dcf8801044868a3f1eb81b52884e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early after 96 steps due to diverging loss.\n",
      "Learning rate set to 0.09120108393559097\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.lr_find_a03f542a-b672-48e6-a66a-b6bfb7b3e801.ckpt\n",
      "LR finder stopped early after 95 steps due to diverging loss.\n",
      "Learning rate set to 0.09120108393559097\n",
      "LR finder stopped early after 97 steps due to diverging loss.\n",
      "LR finder stopped early after 98 steps due to diverging loss.\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.lr_find_27aca894-7114-45d7-92d3-d1ba9f2cc5aa.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.lr_find_a03f542a-b672-48e6-a66a-b6bfb7b3e801.ckpt\n",
      "Learning rate set to 2.5118864315095797e-06\n",
      "Learning rate set to 0.13182567385564073\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.lr_find_ee707df6-9bae-45da-bc70-f172691a3796.ckpt\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.lr_find_3967dfbf-0682-477e-93d5-6a7b066282ba.ckpt\n",
      "LR finder stopped early after 97 steps due to diverging loss.\n",
      "Learning rate set to 0.10964781961431852\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.lr_find_31ad5ad8-d902-49e0-9a0a-61e2b4ebed9b.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.lr_find_27aca894-7114-45d7-92d3-d1ba9f2cc5aa.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.lr_find_ee707df6-9bae-45da-bc70-f172691a3796.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.lr_find_3967dfbf-0682-477e-93d5-6a7b066282ba.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.lr_find_31ad5ad8-d902-49e0-9a0a-61e2b4ebed9b.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8192 succeeded, trying batch size 16384\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8192 succeeded, trying batch size 16384\n",
      "Batch size 8192 succeeded, trying batch size 16384\n",
      "Batch size 8192 succeeded, trying batch size 16384\n",
      "Batch size 8192 succeeded, trying batch size 16384\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16384 succeeded, trying batch size 32768\n",
      "Batch size 16384 succeeded, trying batch size 32768\n",
      "Batch size 16384 succeeded, trying batch size 32768\n",
      "Batch size 16384 succeeded, trying batch size 32768\n",
      "Batch size 16384 succeeded, trying batch size 32768\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "The batch size 32768 is greater or equal than the length of your dataset.\n",
      "Finished batch size finder, will continue with full run using batch size 32768\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "The batch size 32768 is greater or equal than the length of your dataset.\n",
      "Finished batch size finder, will continue with full run using batch size 32768\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "The batch size 32768 is greater or equal than the length of your dataset.\n",
      "Finished batch size finder, will continue with full run using batch size 32768\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "The batch size 32768 is greater or equal than the length of your dataset.\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Finished batch size finder, will continue with full run using batch size 32768\n",
      "The batch size 32768 is greater or equal than the length of your dataset.\n",
      "Finished batch size finder, will continue with full run using batch size 32768\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_e3429e0e-871a-41d9-9e5c-d92dedd6e99c.ckpt\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_300de2ee-a936-4d4a-93d3-1cb0d48e259e.ckpt\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_72ccff03-ee56-4b48-983a-7e4c42bcb251.ckpt\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_5a8ee465-bd46-4ffc-8f32-aaca61e11870.ckpt\n",
      "Restoring states from the checkpoint path at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_8a827914-556b-40d3-8901-76b2367e9ffd.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_e3429e0e-871a-41d9-9e5c-d92dedd6e99c.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_300de2ee-a936-4d4a-93d3-1cb0d48e259e.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_72ccff03-ee56-4b48-983a-7e4c42bcb251.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_8a827914-556b-40d3-8901-76b2367e9ffd.ckpt\n",
      "Restored all states from the checkpoint at /home/scoop/experimentation/experiments/iter1/.scale_batch_size_5a8ee465-bd46-4ffc-8f32-aaca61e11870.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | TCN  | 212 K  | train\n",
      "---------------------------------------\n",
      "212 K     Trainable params\n",
      "0         Non-trainable params\n",
      "212 K     Total params\n",
      "0.851     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7beeb8f7574d87af085e8c9f033ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | TCN  | 212 K  | train\n",
      "---------------------------------------\n",
      "212 K     Trainable params\n",
      "0         Non-trainable params\n",
      "212 K     Total params\n",
      "0.851     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | TCN  | 212 K  | train\n",
      "---------------------------------------\n",
      "212 K     Trainable params\n",
      "0         Non-trainable params\n",
      "212 K     Total params\n",
      "0.851     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | TCN  | 212 K  | train\n",
      "---------------------------------------\n",
      "212 K     Trainable params\n",
      "0         Non-trainable params\n",
      "212 K     Total params\n",
      "0.851     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | TCN  | 212 K  | train\n",
      "---------------------------------------\n",
      "212 K     Trainable params\n",
      "0         Non-trainable params\n",
      "212 K     Total params\n",
      "0.851     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b8ecaa05124411baed0e28f56897dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98e336a5ed844588bb9f68f354c544e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32be614693984b1999fc615649d588c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7257705f9ea4a0e9a42f4402d47f611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbad7a18689c4e658ef45dca8279ae7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aac2c196b794722958dee44572da93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512d06ae0b6540a19bedbc88a920e715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66aa6393552f4bc4842f30af897d66ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85c4adba0f4435393a7e5e2d8e75c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f6d025b84544509b3dd1d3559f5d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65f59e257ba4b55a109f0de6d22e6c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5f72d2e2664826a387b93612e923b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc788a5156b242f2a4b5da58bc148884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e5ab19ab88c4a5cbe5f68d07be2dac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3f0b091d694c05b2f94e19c33d4cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0816df59a6614655a56438ecd038dba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d124697b4fe4f739f661bdb42c55006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b913ba5b69c44125823a001bbeaee3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ece0f8580084af9b3bda41c5a34871b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert time_horizon > 0, \"Time horizon must be a positive integer\"\n",
    "    \n",
    "df = pd.read_csv(nist_path)\n",
    "\n",
    "cleaner = TempCleaner(clean_pow_low, clean_in_low, clean_in_high, clean_out_low, clean_out_high, clean_delta_temp)\n",
    "splitter = StdSplitter(train_days, val_days, test_days)\n",
    "    \n",
    "model = TCN(hidden_size, num_layers, input_size, time_horizon, dropout, seq_len)\n",
    "trainer = TrainerWrapper(L.Trainer, \n",
    "                         max_epochs=num_epochs, \n",
    "                         callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.0, patience=3, verbose=False, mode='min', strict=True)], \n",
    "                         gradient_clip_val=gradient_clipping)\n",
    "optimizer = OptimizerWrapper(optim.Adam, model, lr=learning_rate)\n",
    "\n",
    "model = MonteCarloPipeline.Builder() \\\n",
    "    .add_data(df) \\\n",
    "    .set_cleaner(cleaner) \\\n",
    "    .set_normalizer_class(MinMaxNormalizer) \\\n",
    "    .set_splitter(splitter) \\\n",
    "    .set_sequencer_class(AllTimeSequencer) \\\n",
    "    .set_target_column(TARGET_COLUMN) \\\n",
    "    .set_model(model) \\\n",
    "    .set_optimizer(optimizer) \\\n",
    "    .set_batch_size(batch_size) \\\n",
    "    .set_seq_len(seq_len) \\\n",
    "    .set_worker_num(NUM_WORKERS) \\\n",
    "    .set_error(NRMSE) \\\n",
    "    .set_train_error(RMSE) \\\n",
    "    .set_trainer(trainer) \\\n",
    "    .set_tuner_class(StdTunerWrapper) \\\n",
    "    .set_inference_samples(inference_samples) \\\n",
    "    .set_inference_dropout(inference_dropout) \\\n",
    "    .build()\n",
    "\n",
    "model = EnsemblePipeline.Builder() \\\n",
    "        .set_pipeline(model) \\\n",
    "        .set_num_ensembles(num_ensembles) \\\n",
    "        .add_test_error(NRMSE) \\\n",
    "        .add_test_error(NMLSCV) \\\n",
    "        .add_test_error(NMCRPS) \\\n",
    "        .set_horizon_len(time_horizon) \\\n",
    "        .build()\n",
    "\n",
    "model.fit()\n",
    "ensemple_val_loss_arr = model.get_validation_loss()\n",
    "print(\"VALIDATION LOSS GRAPH\")\n",
    "for loss_arr in ensemple_val_loss_arr:\n",
    "    plot_loss(loss_arr)\n",
    "ensemple_train_loss_arr = model.get_training_loss()\n",
    "print(\"TRAINING LOSS GRAPH\")\n",
    "for loss_arr in ensemple_train_loss_arr:\n",
    "    plot_loss(loss_arr)\n",
    "    \n",
    "model.save(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e4cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.iter1.util.evaluate import evaluate_model\n",
    "df = pd.read_csv(nist_path)\n",
    "\n",
    "cleaner = TempCleaner(clean_pow_low, clean_in_low, clean_in_high, clean_out_low, clean_out_high, clean_delta_temp)\n",
    "splitter = StdSplitter(train_days, val_days, test_days)\n",
    "    \n",
    "model = TCN(hidden_size, num_layers, input_size, time_horizon, dropout, seq_len)\n",
    "trainer = TrainerWrapper(L.Trainer, \n",
    "                         max_epochs=num_epochs, \n",
    "                         callbacks=[EarlyStopping(monitor='val_loss', min_delta=0.0, patience=3, verbose=False, mode='min', strict=True)], \n",
    "                         gradient_clip_val=gradient_clipping)\n",
    "optimizer = OptimizerWrapper(optim.Adam, model, lr=learning_rate)\n",
    "\n",
    "model = MonteCarloPipeline.Builder() \\\n",
    "    .add_data(df) \\\n",
    "    .set_cleaner(cleaner) \\\n",
    "    .set_normalizer_class(MinMaxNormalizer) \\\n",
    "    .set_splitter(splitter) \\\n",
    "    .set_sequencer_class(AllTimeSequencer) \\\n",
    "    .set_target_column(TARGET_COLUMN) \\\n",
    "    .set_model(model) \\\n",
    "    .set_optimizer(optimizer) \\\n",
    "    .set_batch_size(batch_size) \\\n",
    "    .set_seq_len(seq_len) \\\n",
    "    .set_worker_num(NUM_WORKERS) \\\n",
    "    .set_error(NRMSE) \\\n",
    "    .set_train_error(RMSE) \\\n",
    "    .set_trainer(trainer) \\\n",
    "    .set_tuner_class(StdTunerWrapper) \\\n",
    "    .set_inference_samples(inference_samples) \\\n",
    "    .set_inference_dropout(inference_dropout) \\\n",
    "    .build()\n",
    "\n",
    "model = EnsemblePipeline.Builder() \\\n",
    "        .set_pipeline(model) \\\n",
    "        .set_num_ensembles(num_ensembles) \\\n",
    "        .add_test_error(NRMSE) \\\n",
    "        .add_test_error(NMLSCV) \\\n",
    "        .add_test_error(NMCRPS) \\\n",
    "        .set_horizon_len(time_horizon) \\\n",
    "        .build()\n",
    "\n",
    "model.load(MODEL_PATH)\n",
    "model.test()\n",
    "\n",
    "evaluate_model(model, df, splitter, cleaner, TIMESTAMP, POWER, on_limit_w, off_limit_w, consecutive_points, seq_len, time_horizon, TARGET_COLUMN, error, temp_boundary, 0.95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
