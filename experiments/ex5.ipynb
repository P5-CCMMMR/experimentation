{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1230e463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Finding best initial lr:  98%|█████████▊| 98/100 [00:05<00:00, 22.31it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|██████████| 100/100 [00:05<00:00, 18.17it/s]\n",
      "Learning rate set to 4.786300923226383e-07\n",
      "Restoring states from the checkpoint path at /home/vind/P5/experimentation/experiments/.lr_find_0b14d4ed-3228-4e8a-81cf-839dfed7a1ec.ckpt\n",
      "Restored all states from the checkpoint at /home/vind/P5/experimentation/experiments/.lr_find_0b14d4ed-3228-4e8a-81cf-839dfed7a1ec.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2 succeeded, trying batch size 4\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4 succeeded, trying batch size 8\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8 succeeded, trying batch size 16\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 16 succeeded, trying batch size 32\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 32 succeeded, trying batch size 64\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 64 succeeded, trying batch size 128\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 128 succeeded, trying batch size 256\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 256 succeeded, trying batch size 512\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 512 succeeded, trying batch size 1024\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 1024 succeeded, trying batch size 2048\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 2048 succeeded, trying batch size 4096\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 4096 succeeded, trying batch size 8192\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "Batch size 8192 succeeded, trying batch size 16384\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n",
      "The batch size 16384 is greater or equal than the length of your dataset.\n",
      "Finished batch size finder, will continue with full run using batch size 16384\n",
      "Restoring states from the checkpoint path at /home/vind/P5/experimentation/experiments/.scale_batch_size_c8b2c1d7-9590-4831-b40f-2cc75f416625.ckpt\n",
      "Restored all states from the checkpoint at /home/vind/P5/experimentation/experiments/.scale_batch_size_c8b2c1d7-9590-4831-b40f-2cc75f416625.ckpt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.10/multiprocessing/util.py\", line 133, in _remove_temp_dir\n",
      "    rmtree(tempdir)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 731, in rmtree\n",
      "    onerror(os.rmdir, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 729, in rmtree\n",
      "    os.rmdir(path)\n",
      "OSError: [Errno 39] Directory not empty: '/tmp/pymp-ah9mm5ky'\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type | Params | Mode \n",
      "---------------------------------------\n",
      "0 | model | LSTM | 13.4 K | train\n",
      "---------------------------------------\n",
      "13.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.4 K    Total params\n",
      "0.054     Total estimated model params size (MB)\n",
      "3         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 71/71 [00:01<00:00, 44.69it/s, v_num=6, train_loss_step=0.0791, val_loss=0.0852, train_loss_epoch=0.102]   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 14.07it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     test_loss_epoch        10.232137680053711\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Calculating mafe...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "__len__() should return >= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 140\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalculating mafe...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(model, ProbabilisticPipeline)):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROB MAFE ON:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mget_prob_mafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_boundary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_horizon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET_COLUMN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex_confidence\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROB MAFE OFF:\u001b[39m\u001b[38;5;124m\"\u001b[39m, get_prob_mafe(off_data, model, seq_len, error, temp_boundary, time_horizon, TARGET_COLUMN, flex_confidence))\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/P5/experimentation/src/util/flex_error.py:23\u001b[0m, in \u001b[0;36mget_prob_mafe\u001b[0;34m(data, model, seq_len, error, boundary, time_horizon, target_column, confidence)\u001b[0m\n\u001b[1;32m     20\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TimeSequencer(data[\u001b[38;5;241m0\u001b[39m], seq_len, time_horizon, target_column)\n\u001b[1;32m     21\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     24\u001b[0m     input_data, result_actual \u001b[38;5;241m=\u001b[39m batch  \n\u001b[1;32m     26\u001b[0m     last_in_temp  \u001b[38;5;241m=\u001b[39m input_data[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, target_column \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \n",
      "File \u001b[0;32m~/P5/experimentation/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/P5/experimentation/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/P5/experimentation/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:620\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/P5/experimentation/.venv/lib/python3.10/site-packages/torch/utils/data/sampler.py:288\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m batch \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m    287\u001b[0m idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[1;32m    289\u001b[0m     batch[idx_in_batch] \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m    290\u001b[0m     idx_in_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/P5/experimentation/.venv/lib/python3.10/site-packages/torch/utils/data/sampler.py:112\u001b[0m, in \u001b[0;36mSequentialSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_source\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[0;31mValueError\u001b[0m: __len__() should return >= 0"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Assuming your project directory is one level up from the Jupyter notebook\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from src.pipelines.trainers.trainerWrapper import TrainerWrapper\n",
    "from src.util.conditional_early_stopping import ConditionalEarlyStopping\n",
    "from src.util.flex_error import get_mafe, get_prob_mafe\n",
    "from src.util.plot import plot_results\n",
    "from src.util.power_splitter import PowerSplitter\n",
    "from src.util.error import MNLL, NRMSE\n",
    "\n",
    "from src.pipelines.cleaners.temp_cleaner import TempCleaner\n",
    "from src.pipelines.models.lstm import LSTM\n",
    "from src.pipelines.normalizers.min_max_normalizer import MinMaxNormalizer\n",
    "from src.pipelines.sequencers.time_sequencer import TimeSequencer\n",
    "from src.pipelines.splitters.std_splitter import StdSplitter\n",
    "from src.pipelines.tuners.std_tuner_wrapper import StdTunerWrapper\n",
    "from src.pipelines.optimizers.optimizer import OptimizerWrapper\n",
    "\n",
    "from src.pipelines.deterministic_pipeline import DeterministicPipeline\n",
    "from src.pipelines.monte_carlo_pipeline import MonteCarloPipeline\n",
    "from src.pipelines.ensemble_pipeline import EnsemblePipeline\n",
    "from src.pipelines.probabilistic_pipeline import ProbabilisticPipeline\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "MODEL_PATH = 'model.pth'\n",
    "NUM_WORKERS = multiprocessing.cpu_count()\n",
    "TARGET_COLUMN = 2\n",
    "TIMESTAMP = \"Timestamp\"\n",
    "POWER     = \"PowerConsumption\"\n",
    "\n",
    "# Hyper parameters\n",
    "# Model\n",
    "input_size = 4\n",
    "time_horizon = 4\n",
    "hidden_size = 32\n",
    "num_epochs = 1000\n",
    "seq_len = 96\n",
    "num_layers = 2\n",
    " \n",
    "# MC ONLY\n",
    "inference_samples = 50\n",
    "\n",
    "# Training\n",
    "dropout = 0.50\n",
    "gradient_clipping = 0\n",
    "early_stopping_threshold = 0.15\n",
    "\n",
    "num_ensembles = 5\n",
    "\n",
    "# Flexibility\n",
    "flex_confidence = 0.90\n",
    "temp_boundary = 0.1\n",
    "error = 0\n",
    "\n",
    "# Controlled by tuner\n",
    "batch_size = 128\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Data Split\n",
    "train_days = 16\n",
    "val_days = 2\n",
    "test_days = 2\n",
    "\n",
    "# ON / OFF Power Limits\n",
    "off_limit_w = 100\n",
    "on_limit_w = 1500\n",
    "\n",
    "consecutive_points = 3\n",
    "\n",
    "nist_path = \"../src/data_preprocess/dataset/NIST_cleaned.csv\"\n",
    "\n",
    "clean_in_low = 10\n",
    "clean_in_high = 30\n",
    "clean_out_low = -50\n",
    "clean_out_high = 50\n",
    "clean_pow_low = 0\n",
    "clean_delta_temp = 15\n",
    "\n",
    "assert time_horizon > 0, \"Time horizon must be a positive integer\"\n",
    "    \n",
    "df = pd.read_csv(nist_path)\n",
    "\n",
    "cleaner = TempCleaner(clean_pow_low, clean_in_low, clean_in_high, clean_out_low, clean_out_high, clean_delta_temp)\n",
    "splitter = StdSplitter(train_days, val_days, test_days)\n",
    "    \n",
    "model = LSTM(hidden_size, num_layers, input_size, time_horizon, dropout)\n",
    "trainer = TrainerWrapper(L.Trainer, \n",
    "                         max_epochs=num_epochs, \n",
    "                         callbacks=[ConditionalEarlyStopping(threshold=early_stopping_threshold)], \n",
    "                         gradient_clip_val=gradient_clipping)\n",
    "optimizer = OptimizerWrapper(optim.Adam, model, lr=learning_rate)\n",
    "\n",
    "model = MonteCarloPipeline.Builder() \\\n",
    "    .add_data(df) \\\n",
    "    .set_cleaner(cleaner) \\\n",
    "    .set_normalizer_class(MinMaxNormalizer) \\\n",
    "    .set_splitter(splitter) \\\n",
    "    .set_sequencer_class(TimeSequencer) \\\n",
    "    .set_target_column(TARGET_COLUMN) \\\n",
    "    .set_model(model) \\\n",
    "    .set_optimizer(optimizer) \\\n",
    "    .set_batch_size(batch_size) \\\n",
    "    .set_seq_len(seq_len) \\\n",
    "    .set_worker_num(NUM_WORKERS) \\\n",
    "    .set_error(NRMSE) \\\n",
    "    .set_trainer(trainer) \\\n",
    "    .set_tuner_class(StdTunerWrapper) \\\n",
    "    .set_inference_samples(inference_samples) \\\n",
    "    .set_test_error(MNLL) \\\n",
    "    .build()\n",
    "\n",
    "model.fit()\n",
    "model.test()\n",
    "\n",
    "plot_results(model.get_predictions(), model.get_actuals(), model.get_timestamps())\n",
    "\n",
    "model.eval()\n",
    "\n",
    "ps = PowerSplitter(splitter.get_test(cleaner.clean(df)), TIMESTAMP, POWER)\n",
    "\n",
    "on_df = ps.get_mt_power(on_limit_w, consecutive_points)\n",
    "off_df = ps.get_lt_power(off_limit_w, consecutive_points)\n",
    "\n",
    "on_data = np.array(on_df)\n",
    "off_data = np.array(off_df)\n",
    "\n",
    "print(\"Calculating mafe...\")\n",
    "if (isinstance(model, ProbabilisticPipeline)):\n",
    "    print(\"PROB MAFE ON:\", get_prob_mafe(on_data, model, seq_len, error, temp_boundary, time_horizon, TARGET_COLUMN, flex_confidence))\n",
    "    print(\"PROB MAFE OFF:\", get_prob_mafe(off_data, model, seq_len, error, temp_boundary, time_horizon, TARGET_COLUMN, flex_confidence))\n",
    "else:\n",
    "    print(\"MAFE ON:\", get_mafe(on_data, model, seq_len, error, temp_boundary, time_horizon, TARGET_COLUMN))\n",
    "    print(\"MAFE OFF:\", get_mafe(off_data, model, seq_len, error, temp_boundary, time_horizon, TARGET_COLUMN))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
